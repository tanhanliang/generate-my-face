"""
Builds the discriminator and the generator.
"""
import keras.models as models
import keras.layers as layers
import keras.optimizers as opt
import models.parameters as params
import numpy as np
from keras.layers import Input
from keras.models import Model
import keras.backend as K


class GAN:
    def __init__(self, lmbda, k_t, gamma, norm):
        """
        Builds and wires up the models.
        See https://blog.heuritech.com/2017/04/11/began-state-of-the-art-generation-of-faces-with-generative-adversarial-networks/

        :param lmbda: The learning rate for get_kt
        :param k_t: The adaptive term that balances the losses of the discriminator and
        generator automatically
        :param gamma: The tradeoff between image diversity and quality
        :param norm: L1 norm or L2 norm. An integer in {1, 2}
        """
        self.lmbda = lmbda
        self.k_t = K.variable(k_t)
        self.r_reconst_loss = None
        self.gen_loss = None
        self.discrim_loss = None
        self.gamma = gamma
        self.norm = norm

        self.generator = build_autoencoder()
        g_optimiser = opt.adam(lr=params.LEARNING_RATE)
        self.generator.compile(loss=self.generator_loss,
                                    optimizer=g_optimiser,
                                    metrics=['accuracy'])
        self.discriminator = build_autoencoder()
        d_optimiser = opt.adam(lr=params.LEARNING_RATE)
        self.discriminator.compile(loss=self.discriminator_loss,
                                   optimizer=d_optimiser,
                                   metrics=['accuracy',
                                            self.get_kt,
                                            self.get_discrim_loss,
                                            self.get_r_reconstr_loss])
        self.discriminator.trainable = False

        # Connect the generator to the discriminator
        gan_input = Input(shape=params.NOISE_SHAPE)
        generated_img = self.generator(gan_input)
        discrim_out = self.discriminator(generated_img)

        # Build and compile the full GAN
        self.combined_model = Model(gan_input, discrim_out)
        g_optimiser = opt.adam(lr=params.LEARNING_RATE)
        self.combined_model.compile(loss=self.generator_loss,
                                    optimizer=g_optimiser,
                                    metrics=['accuracy',
                                             self.get_gen_loss])

    # For the callbacks
    def get_kt(self, y_true, y_pred):
        # y_true and y_pred are 4d tensors
        return self.k_t

    def get_gen_loss(self, y_true, y_pred):
        # y_true and y_pred are 4d tensors
        return self.gen_loss

    def get_discrim_loss(self, y_true, y_pred):
        # y_true and y_pred are 4d tensors
        return self.discrim_loss

    def get_r_reconstr_loss(self, y_true, y_pred):
        # y_true and y_pred are 4d tensors
        return self.r_reconst_loss

    def discriminator_loss(self, y_true, y_pred):
        """
        Custom loss function for Keras. This function is a function of the reconstruction losses
        of both the discriminator and generator.

        The reconstruction loss of the discriminator measures how well it is able to reconstruct
        images of hanliang when passed images of hanliang.

        The reconstruction loss of the generator measures how well it is able to generate an image
        from random noise to minimise the reconstruction loss when this generated image is passed
        to the discriminator.

        The discriminator has two competing objectives. The first is to learn how to encode pictures
        of hanliang, the second is to learn how not to encode pictures generated by the generator.
        In other words, on the one hand it can learn features of hanliang, on the other hand it
        can learn not to encode features in generated images.

        Working towards the first objective creates more accurate images, and working towards the second
        objective creates more diverse images. The tradeoff can be controlled by the gamma parameter.

        See the blog post link above for the full details.

        L_D = real_reconstr_loss - get_kt*get_gen_loss
        L_G = get_gen_loss

        :param y_true: The images passed to the autoencoder.A Tensor
        :param y_pred: The images reconstructed by the autoencoder. A Tensor
        :return: A float
        """
        if self.gen_loss is None:
            raise ValueError("gen_loss is None and has not been initialised.")

        real_reconst_loss = self.get_real_reconstr_loss(y_true, y_pred)

        # # Now calculate the discriminator loss
        self.discrim_loss = real_reconst_loss - self.k_t*self.gen_loss
        self.update_kt(real_reconst_loss, self.gen_loss)

        return K.cast(self.discrim_loss, dtype=np.float32)

    def get_real_reconstr_loss(self, y_true, y_pred):
        """
        Gets the reconstruction loss for real images in the discriminator

        :param y_true: A tensor
        :param y_pred: A tensor
        :return: A tensor
        """

        discrim_loss_per_pix = K.pow(K.abs(y_pred - y_true), self.norm)
        self.r_reconst_loss = K.mean(discrim_loss_per_pix)
        return self.r_reconst_loss

    def generator_loss(self, y_true, y_pred):
        """
        The loss function for the generator. This computes a simple sum of differences
        between real and reconstructed images.

        Alternative: When training the generator, pass the input noise to y_true also,
        then use it here. It will obfuscate the code more though...

        :param y_true: The fake images generated by the generator
        :param y_pred: The images reconstructed by discriminator.
        :return: A float
        """
        gen_loss_per_pix = K.pow(K.abs(y_pred - y_true), self.norm)
        self.gen_loss = K.mean(gen_loss_per_pix)
        return self.gen_loss

    def update_kt(self, real_reconst_loss, gen_loss):
        """
        Update rule for get_kt.

        get_kt+1 = get_kt + lmbda*(gamma*get_discrim_loss - get_gen_loss)

        In a perfect world, gamma*get_discrim_loss - get_gen_loss == 0. This represents the stable point,
        which the adaptive parameter get_kt strives to reach. Let me attempt an intuitive explanation
        to test my understanding of this. To recap, the losses for The discriminator and generator
        are:

        L_D = get_discrim_loss - get_kt*get_gen_loss
        L_G = get_gen_loss

        If:

        (1) get_gen_loss << get_discrim_loss: generator is getting too good at producing fake images, or
            discriminator is getting lousy at its reconstruction task.
            get_kt increases, incentive for discriminator to get better at its discrimination task
            increases (incentive for discriminator to increase get_gen_loss)
        (2) get_gen_loss >> get_discrim_loss: discriminator is getting too good at its encoding task, or
            generator is too lousy at producing fake images.
            get_kt decreases, causing a penalty on L_D which helps to prevent it from getting lower.

        :param real_reconst_loss: The reconstruction loss when passing a real image to the discriminator
        :param gen_loss: The reconstruction loss when passing a fake image to the generator
        :return: Nothing
        """
        self.k_t = K.update_add(self.k_t, self.lmbda * (self.gamma * real_reconst_loss - gen_loss))
        return self.k_t

    def print_convergence_measures(self, epoch, callback):
        """
        Computes a measure of convergence for the GAN.
        M_global = get_discrim_loss + abs(gamma*get_discrim_loss - get_gen_loss)

        :param epoch: The training step
        :return: Nothing
        """
        gen_loss = callback.metrics["get_gen_loss"]
        discrim_loss = callback.metrics["get_discrim_loss"]
        real_reconstr_loss = callback.metrics["get_r_reconstr_loss"]
        kt = callback.metrics["get_kt"]
        # conv_val = reconst_loss + abs(self.gamma*reconst_loss - get_gen_loss)

        print("Epoch %d: [get_gen_loss: %f] [get_discrim_loss: %f, reconst_loss: %f] [M_global: f] [get_kt: %f]" %
              (epoch, gen_loss, discrim_loss, real_reconstr_loss, kt))


def build_autoencoder():
    """
    Builds an autoencoder which attempts to learn common features in pictures of hanliang.

    :return: A keras Model
    """

    # model = models.Sequential()
    # model.add(layers.Convolution2D(32, (5, 5), activation="relu", input_shape=params.IMG_SHAPE))
    # model.add(layers.MaxPooling2D(pool_size=(5, 5)))
    # model.add(layers.Convolution2D(32, (5, 5), activation="relu")
    # model.add(layers.MaxPooling2D(pool_size=(5, 5)))
    # model.add(layers.Flatten())
    # model.add(layers.Dense(64, activation="relu"))
    # model.add(layers.Dense(64, activation="relu"))
    # model.add(layers.Dense(1, activation="sigmoid"))
    padding_size = (1, 1)
    kernel_size = (3, 3)
    filters = 32

    model = models.Sequential()
    # Start of encoder
    # Shape is still the original image shape
    model.add(layers.ZeroPadding2D(padding=padding_size, input_shape=params.IMG_SHAPE))
    model.add(layers.Convolution2D(filters, kernel_size, activation="elu"))
    model.add(layers.ZeroPadding2D(padding=padding_size))
    model.add(layers.Convolution2D(filters, kernel_size, activation="elu"))
    model.add(layers.ZeroPadding2D(padding=padding_size))
    model.add(layers.Convolution2D(filters, kernel_size, activation="elu"))

    # Shape now has half the width and height of the original
    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
    model.add(layers.ZeroPadding2D(padding=padding_size))
    model.add(layers.Convolution2D(filters, kernel_size, activation="elu"))
    model.add(layers.ZeroPadding2D(padding=padding_size))
    model.add(layers.Convolution2D(filters, kernel_size, activation="elu"))

    # Shape is now a quarter the width and height of the original
    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
    model.add(layers.ZeroPadding2D(padding=padding_size))
    model.add(layers.Convolution2D(filters, kernel_size, activation="elu"))
    model.add(layers.ZeroPadding2D(padding=padding_size))
    model.add(layers.Convolution2D(filters, kernel_size, activation="elu"))

    # Shape is now an eight the width and height of the original
    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
    model.add(layers.ZeroPadding2D(padding=padding_size))
    model.add(layers.Convolution2D(filters, kernel_size, activation="elu"))
    model.add(layers.ZeroPadding2D(padding=padding_size))
    model.add(layers.Convolution2D(filters, kernel_size, activation="elu"))
    model.add(layers.Dense(128))

    # Start of decoder
    model.add(layers.Dense(128))
    model.add(layers.ZeroPadding2D(padding=padding_size))
    model.add(layers.Convolution2D(filters, kernel_size, activation="elu"))
    model.add(layers.ZeroPadding2D(padding=padding_size))
    model.add(layers.Convolution2D(filters, kernel_size, activation="elu"))

    # Shape is a quarter the width and height of the original
    model.add(layers.UpSampling2D(size=(2, 2)))
    model.add(layers.ZeroPadding2D(padding=padding_size))
    model.add(layers.Convolution2D(filters, kernel_size, activation="elu"))
    model.add(layers.ZeroPadding2D(padding=padding_size))
    model.add(layers.Convolution2D(filters, kernel_size, activation="elu"))

    # Shape is now half the width and height of the original
    model.add(layers.UpSampling2D(size=(2, 2)))
    model.add(layers.ZeroPadding2D(padding=padding_size))
    model.add(layers.Convolution2D(filters, kernel_size, activation="elu"))
    model.add(layers.ZeroPadding2D(padding=padding_size))
    model.add(layers.Convolution2D(filters, kernel_size, activation="elu"))

    # Shape is now the original size
    model.add(layers.UpSampling2D(size=(2, 2)))
    model.add(layers.ZeroPadding2D(padding=padding_size))
    model.add(layers.Convolution2D(filters, kernel_size, activation="elu"))
    model.add(layers.ZeroPadding2D(padding=padding_size))
    model.add(layers.Convolution2D(filters, kernel_size, activation="elu"))
    model.add(layers.ZeroPadding2D(padding=padding_size))
    model.add(layers.Convolution2D(params.CHANNELS, kernel_size, activation="tanh"))

    return model
